# NIPS 2017 Resources

# Slides

## Tutorials
*  [Deep Learning -- Trends and Practices](https://docs.google.com/presentation/d/e/2PACX-1vQMZsWfjjLLz_wi8iaMxHKawuTkdqeA3Gw00wy5dBHLhAkuLEvhB7k-4LcO5RQEVFzZXfS6ByABaRr4/pub?start=false&loop=false&delayms=60000#slide=id.p)
*  [Deep Probabilistic Modelling with Gaussian Processes](http://inverseprobability.com/talks/lawrence-nips17/deep-probabilistic-modelling-with-gaussian-processes.html)
*  [Fairness in Machine Learning](http://mrtz.org/nips17/#/)
*  [Differentially Private Machine Learning Theory, Algorithms, and Applications](http://www.ece.rutgers.edu/~asarwate/nips2017/NIPS17_DPML_Tutorial.pdf)


## Talks
*  [Machine Learning for Systems and Systems for Machine Learning](http://learningsys.org/nips17/assets/slides/dean-nips17.pdf)
*  [Deep Learning for Robotics](https://www.dropbox.com/s/3fkewk7yks4c2id/2017_12_xx_NIPS%20workshop%20robotics%20final.pdf?dl=0)
*  [Safety Challenges for RL in Robotics](https://www.dropbox.com/s/kzj72mjws75g7nv/2017_12_xx_NIPS%20learning%20in%20transportation.pdf?dl=0)
*  [Learning to Learn for Robotic Control](https://www.dropbox.com/s/ej71t553vlw4yw7/2017_12_xx_NIPS-meta-learning-symposium-Abbeel.pdf?dl=0)
*  [The Role of Causality for Interpretability](http://s.interpretable.ml/nips_interpretable_ml_2017_Bernhard_Schoelkopf.pdf)
*  [Interpretable Discovery in Large Image Data Sets](http://s.interpretable.ml/nips_interpretable_ml_2017_kiri_wagstaff.pdf)
*  [The Cost Of Calibration](http://s.interpretable.ml/nips_interpretable_ml_2017_Kilian_Weinberger.pdf)
*  [Interpretability for AI safety](http://s.interpretable.ml/nips_interpretable_ml_2017_victoria_Krakovna.pdf)
*  [Manipulating and Measuring Model Interpretability](http://s.interpretable.ml/nips_interpretable_ml_2017_jenn_wortman_vaughan.pdf)
*  [Debugging the Machine Learning Pipeline](http://s.interpretable.ml/nips_interpretable_ml_2017_jerry_zhu.pdf)
*  [Variational inference for deep Gaussian processes](http://adamian.github.io/talks/Damianou_NIPS17.pdf)
*  [GANs for Limited Labeled Data](http://www.iangoodfellow.com/slides/2017-12-09-label.pdf)
*  [A Tutorial on the Pac-Bayesian Theory](https://bguedj.github.io/nips2017/pdf/laviolette_nips2017.pdf)
*  [A Tight Excess Risk Bound via a Unified PAC-Bayesian-Rademacher-Shtarkov-MDL Complexity](https://bguedj.github.io/nips2017/pdf/grunwald_nips2017.pdf)
*  [Dimension-free PAC-Bayesian Bounds](https://bguedj.github.io/nips2017/pdf/catoni_nips2017_1.pdf)
*  [Estimation of the Mean of a Random Vector](https://bguedj.github.io/nips2017/pdf/catoni_nips2017_2.pdf)
*  [Some Recent Advances on Approximate Bayesian Computation techniques](https://bguedj.github.io/nips2017/pdf/marin_nips2017.pdf)
*  [Deep Neural Networks:  From Flat Minima to Numerically Nonvacuous Generalization Bounds via PAC-Bayes](https://bguedj.github.io/nips2017/pdf/roy_nips2017.pdf)
*  [A Strongly Quasiconvex PAC-Bayesian Bound](https://bguedj.github.io/nips2017/pdf/seldin_nips2017.pdf)
*  [Data Dependent Priors for Stable Learning](https://bguedj.github.io/nips2017/pdf/shawe-taylor_nips2017.pdf)
*  [End to End Optimization Stack for Deep Learning](http://learningsys.org/nips17/assets/slides/TVM-MLSys-NIPS17.pdf)
*  [Autoregressive Generative Networks](https://drive.google.com/file/d/11CNWY5op_J5PvP02J9g8tciAom-MW9MZ/view)


# Notes

*  [NIPS 2017 Notes](https://cs.brown.edu/~dabel/blog/posts/misc/nips_2017.pdf)

# Papers

## Search

*  [Ranking Data with Continuous Labels through Oriented Recursive Partitions](https://papers.nips.cc/paper/7046-ranking-data-with-continuous-labels-through-oriented-recursive-partitions) Stéphan Clémençon, Mastane Achab.
*  [Optimal Sample Complexity of M-wise Data for Top-K Ranking](https://papers.nips.cc/paper/6766-optimal-sample-complexity-of-m-wise-data-for-top-k-ranking) Minje Jang, Sunghyun Kim, Changho Suh, Sewoong Oh.
*  [Maxing and Ranking with Few Assumptions](https://papers.nips.cc/paper/7281-maxing-and-ranking-with-few-assumptions) Moein Falahatgar, Yi Hao, Alon Orlitsky, Venkatadheeraj Pichapati, Vaishakh Ravindrakumar.
*  [Learning with Average Top-k Loss](https://papers.nips.cc/paper/6653-learning-with-average-top-k-loss) Yanbo Fan, Siwei Lyu, Yiming Ying, Baogang Hu.
*  [Few-Shot Learning Through an Information Retrieval Lens](https://papers.nips.cc/paper/6820-few-shot-learning-through-an-information-retrieval-lens) Eleni Triantafillou, Richard Zemel, Raquel Urtasun.


## Recommendation

*  [Scalable Demand-Aware Recommendation](https://papers.nips.cc/paper/6835-scalable-demand-aware-recommendation) Jinfeng Yi, Cho-Jui Hsieh, Kush R. Varshney, Lijun Zhang, Yao Li.
*  [Off-Policy Evaluation for Slate Recommendation](https://papers.nips.cc/paper/6954-off-policy-evaluation-for-slate-recommendation) Adith Swaminathan, Akshay Krishnamurthy, Alekh Agarwal, Miro Dudik, John Langford, Damien Jose, Imed Zitouni.
*  [DropoutNet: Addressing Cold Start in Recommender Systems](https://papers.nips.cc/paper/7081-dropoutnet-addressing-cold-start-in-recommender-systems) Maksims Volkovs, Guangwei Yu, Tomi Poutanen.
*  [A Meta-Learning Perspective on Cold-Start Recommendations for Items](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items) Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, Hugo Larochelle.
*  [Mixture-Rank Matrix Approximation for Collaborative Filtering](https://papers.nips.cc/paper/6651-mixture-rank-matrix-approximation-for-collaborative-filtering) Dongsheng Li, Chao Chen, Wei Liu, Tun Lu, Ning Gu, Stephen Chu.

## Matrix Factorization

*  [On the Power of Truncated SVD for General High-rank Matrix Estimation](https://papers.nips.cc/paper/6648-on-the-power-of-truncated-svd-for-general-high-rank-matrix-estimation-problems) Problems Simon S. Du, Yining Wang, Aarti Singh.
*  [A New Theory for Matrix Completion](https://papers.nips.cc/paper/6680-a-new-theory-for-matrix-completion) Guangcan Liu, Qingshan Liu, Xiaotong Yuan.
*  [Fixed-Rank Approximation of a Positive-Semidefinite Matrix from Streaming Data](https://papers.nips.cc/paper/6722-fixed-rank-approximation-of-a-positive-semidefinite-matrix-from-streaming-data) Joel A. Tropp, Alp Yurtsever, Madeleine Udell, Volkan Cevher.
*  [Implicit Regularization in Matrix Factorization](https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization) Suriya Gunasekar, Blake E. Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur, Nati Srebro.

## Hashing

*  [Hash Embeddings for Efficient Word Representations](https://papers.nips.cc/paper/7078-hash-embeddings-for-efficient-word-representations) Dan Tito Svenstrup, Jonas Hansen, Ole Winther.
*  [Deep Supervised Discrete Hashing](https://papers.nips.cc/paper/6842-deep-supervised-discrete-hashing) Qi Li, Zhenan Sun, Ran He, Tieniu Tan.
*  [Practical Hash Functions for Similarity Estimation and Dimensionality Reduction](https://papers.nips.cc/paper/7239-practical-hash-functions-for-similarity-estimation-and-dimensionality-reduction) Søren Dahlgaard, Mathias Knudsen, Mikkel Thorup.

## Extreme Classification

*  [Aggressive Sampling for Multi-class to Binary Reduction with Applications to Text Classification](https://papers.nips.cc/paper/7004-aggressive-sampling-for-multi-class-to-binary-reduction-with-applications-to-text-classification) Bikash Joshi, Massih-Reza Amini, Ioannis Partalas, Franck Iutzeler, Yury Maximov.

## Embeddings

*  [Context Selection for Embedding Models](https://papers.nips.cc/paper/7067-context-selection-for-embedding-models) Liping Liu, Francisco Ruiz, Susan Athey, David Blei.

## Experimentation

*  [A framework for Multi-A(rmed)/B(andit) Testing with Online FDR Control](https://papers.nips.cc/paper/7177-a-framework-for-multi-armedbandit-testing-with-online-fdr-control) Fanny Yang, Aaditya Ramdas, Kevin G. Jamieson, Martin J. Wainwright.

